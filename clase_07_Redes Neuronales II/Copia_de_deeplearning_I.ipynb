{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Qué es np.memmap?\n",
        "\n",
        "La función np.memmap de NumPy nos permite crear una matriz que está respaldada por un archivo en el disco en lugar de por la memoria del sistema. Esto puede ser útil cuando tenemos archivos de datos muy grandes que no caben en la memoria RAM del sistema, pero necesitamos acceder a ellos de manera eficiente. Con np.memmap, podemos crear una vista a un archivo y trabajar con los datos como si estuvieran almacenados en memoria.\n",
        "\n",
        "## ¿Cómo usar np.memmap?\n",
        "\n",
        "La sintaxis básica para crear un objeto np.memmap es la siguiente:\n",
        "\n",
        "```python\n",
        "np.memmap(filename, dtype='float32', mode='r+', shape=(M, N))\n",
        "```\n",
        "\n",
        "- filename: el nombre del archivo en el disco\n",
        "- dtype: el tipo de datos de los elementos de la matriz (por defecto 'float32')\n",
        "- mode: el modo en que se va a abrir el archivo ('r+' para lectura/escritura, 'r' para sólo lectura)\n",
        "- shape: la forma de la matriz a crear\n",
        "\n",
        "Una vez que hemos creado un objeto np.memmap, podemos trabajar con él como lo haríamos con cualquier otra matriz de NumPy. Por ejemplo, podemos acceder a los elementos de la matriz de la siguiente manera:\n",
        "\n",
        "```python\n",
        "# Crear un objeto np.memmap\n",
        "data = np.memmap('datos.dat', dtype='float32', mode='r+', shape=(1000, 1000))\n",
        "\n",
        "# Acceder a un elemento de la matriz\n",
        "print(data[0, 0])\n",
        "```\n",
        "\n",
        "## ¿Por qué usar np.memmap?\n",
        "\n",
        "La ventaja de usar np.memmap es que podemos trabajar con archivos de datos muy grandes sin tener que cargarlos completamente en la memoria RAM del sistema. Esto puede ser especialmente útil en aplicaciones que requieren el procesamiento de grandes conjuntos de datos, como en el caso de la ciencia de datos o el aprendizaje automático. Al utilizar np.memmap, podemos acceder a los datos de manera eficiente sin tener que preocuparnos por la limitación de la memoria RAM.\n",
        "\n",
        "## Ejemplo de uso de np.memmap\n",
        "\n",
        "```python\n",
        "# Crear un archivo de datos de ejemplo\n",
        "with open('datos.dat', 'wb') as f:\n",
        "    data = np.random.rand(1000, 1000)\n",
        "    data.tofile(f)\n",
        "\n",
        "# Crear un objeto np.memmap\n",
        "data = np.memmap('datos.dat', dtype='float64', mode='r+', shape=(1000, 1000))\n",
        "\n",
        "# Sumar 1 a cada elemento de la matriz\n",
        "data += 1\n",
        "\n",
        "# Calcular la media de la matriz\n",
        "print(np.mean(data))\n",
        "```\n",
        "\n",
        "En este ejemplo, creamos un archivo de datos aleatorios y lo cargamos en un objeto np.memmap. Luego, sumamos 1 a cada elemento de la matriz y calculamos la media. Como puede ver, el uso de np.memmap nos permite trabajar con archivos grandes de manera eficiente y sin tener que preocuparnos por la limitación de la memoria RAM."
      ],
      "metadata": {
        "id": "S-H6jmPuppLD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV2B8jtmhXHe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clases y Métodos en Python\n",
        "\n",
        "En Python, una clase es un tipo de dato que permite encapsular datos y funciones en un solo objeto. Los objetos de una clase se llaman instancias y cada instancia tiene sus propios atributos y métodos. Los atributos son variables que contienen datos y los métodos son funciones que trabajan con los datos.\n",
        "\n",
        "## Definición de una clase\n",
        "\n",
        "Para definir una clase en Python se utiliza la palabra clave `class`, seguida del nombre de la clase en CamelCase (la primera letra de cada palabra en mayúscula) y los dos puntos. Dentro de la clase se definen los atributos y los métodos de la siguiente forma:\n",
        "\n",
        "```python\n",
        "class NombreDeLaClase:\n",
        "    \n",
        "    # Atributos\n",
        "    atributo1 = valor1\n",
        "    atributo2 = valor2\n",
        "    \n",
        "    # Métodos\n",
        "    def nombre_del_metodo(self, parametro1, parametro2):\n",
        "        # Cuerpo del método\n",
        "```\n",
        "\n",
        "Los atributos se definen como variables dentro de la clase, con un nombre y un valor asignado. Los métodos se definen como funciones dentro de la clase, utilizando la sintaxis estándar de Python para definir una función. Todos los métodos deben tener al menos un parámetro, que se llama `self` y que hace referencia a la instancia de la clase que está utilizando el método.\n",
        "\n",
        "## Instanciación de una clase\n",
        "\n",
        "Para utilizar una clase es necesario crear una instancia de la misma. Para crear una instancia se utiliza el nombre de la clase seguido de los paréntesis, como si fuera una función:\n",
        "\n",
        "```python\n",
        "mi_instancia = NombreDeLaClase()\n",
        "```\n",
        "\n",
        "## Atributos\n",
        "\n",
        "Los atributos de una instancia de una clase se pueden acceder y modificar utilizando la sintaxis de punto:\n",
        "\n",
        "```python\n",
        "mi_instancia.atributo1 = nuevo_valor1\n",
        "valor = mi_instancia.atributo2\n",
        "```\n",
        "\n",
        "## Métodos\n",
        "\n",
        "Los métodos de una clase se pueden utilizar utilizando la sintaxis de punto, pasando los parámetros necesarios:\n",
        "\n",
        "```python\n",
        "mi_instancia.nombre_del_metodo(parametro1, parametro2)\n",
        "```\n",
        "\n",
        "## Ejemplo\n",
        "\n",
        "Veamos un ejemplo sencillo para entender mejor cómo funcionan las clases y los métodos en Python. Vamos a crear una clase que representa a una persona, con dos atributos (nombre y edad) y dos métodos (uno para imprimir el nombre y otro para incrementar la edad en uno):\n",
        "\n",
        "```python\n",
        "class Persona:\n",
        "    \n",
        "    # Atributos\n",
        "    nombre = ''\n",
        "    edad = 0\n",
        "    \n",
        "    # Métodos\n",
        "    def imprimir_nombre(self):\n",
        "        print('Mi nombre es', self.nombre)\n",
        "    \n",
        "    def incrementar_edad(self):\n",
        "        self.edad += 1\n",
        "        print('Mi edad es', self.edad)\n",
        "```\n",
        "\n",
        "Ahora vamos a crear una instancia de esta clase y utilizar sus métodos y atributos:\n",
        "\n",
        "```python\n",
        "# Creamos una instancia de la clase Persona\n",
        "mi_persona = Persona()\n",
        "\n",
        "# Modificamos los atributos de la persona\n",
        "mi_persona.nombre = 'Juan'\n",
        "mi_persona.edad = 25\n",
        "\n",
        "# Utilizamos los métodos de la persona\n",
        "mi_persona.imprimir_nombre()\n",
        "mi_persona.incrementar_edad()\n",
        "```\n",
        "\n",
        "Este código imprimirá lo siguiente:\n",
        "\n",
        "```\n",
        "Mi nombre es Juan\n",
        "Mi edad es 26\n",
        "```"
      ],
      "metadata": {
        "id": "_oscmqyGqLQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVjjzb3VrWwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Numpy**\n",
        "\n",
        "Numpy es una biblioteca de Python muy popular para cálculos científicos y matemáticos. Proporciona un poderoso objeto de matriz multidimensional y una gran cantidad de funciones matemáticas para operar en matrices. Es muy útil para realizar cálculos matemáticos y científicos, y se utiliza en una amplia variedad de campos, como la física, la biología y la informática.\n",
        "\n",
        "Por otro lado, Torch es una biblioteca de aprendizaje profundo de código abierto basada en Lua. Fue creada originalmente para el procesamiento de señales y la visión por computadora, pero se ha expandido para incluir muchas otras áreas del aprendizaje profundo. Torch proporciona una API para construir redes neuronales y entrenar modelos, así como un conjunto de herramientas para trabajar con datos, como transformaciones de datos y cargadores de datos.\n",
        "\n",
        "A diferencia de Numpy, que se enfoca principalmente en el cálculo numérico, Torch se enfoca específicamente en el aprendizaje profundo y proporciona herramientas para entrenar y evaluar modelos de aprendizaje profundo. También tiene una estructura de red neuronal integrada y una serie de herramientas para el procesamiento de datos, lo que lo hace más conveniente para tareas de aprendizaje profundo que Numpy.\n"
      ],
      "metadata": {
        "id": "d_pO4W6ds4S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# crear un array en numpy\n",
        "x_np = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# convertir a tensor en PyTorch\n",
        "x_torch = torch.tensor(x_np)\n",
        "\n",
        "print(\"Array en numpy:\")\n",
        "print(x_np)\n",
        "\n",
        "print(\"Tensor en PyTorch:\")\n",
        "print(x_torch)"
      ],
      "metadata": {
        "id": "Tu-V08pQtCBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cuda vs CPU?**"
      ],
      "metadata": {
        "id": "ZK_ljUL4tEyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Creamos dos matrices de 1000x1000\n",
        "a_np = np.random.rand(1000, 1000)\n",
        "b_np = np.random.rand(1000, 1000)\n",
        "\n",
        "a_torch = torch.from_numpy(a_np)\n",
        "b_torch = torch.from_numpy(b_np)\n",
        "\n",
        "# Multiplicación de matrices con NumPy\n",
        "start_np = time.time()\n",
        "c_np = np.dot(a_np, b_np)\n",
        "end_np = time.time()\n",
        "\n",
        "# Multiplicación de matrices con Torch + CUDA\n",
        "start_torch = time.time()\n",
        "a_cuda = a_torch.cuda()\n",
        "b_cuda = b_torch.cuda()\n",
        "c_torch = torch.mm(a_cuda, b_cuda)\n",
        "c_np = c_torch.cpu().numpy()\n",
        "end_torch = time.time()\n",
        "\n",
        "print(f\"Tiempo con NumPy: {end_np - start_np} segundos\")\n",
        "print(f\"Tiempo con Torch + CUDA: {end_torch - start_torch} segundos\")"
      ],
      "metadata": {
        "id": "tXHL3y7rtxRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db726e50-4cf4-4e68-c099-a86c16e9fa6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo con NumPy: 0.07703661918640137 segundos\n",
            "Tiempo con Torch + CUDA: 0.03894352912902832 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **¿Que es un dataloader?**\n",
        "\n",
        "Un DataLoader en el contexto del aprendizaje profundo es una utilidad que ayuda a cargar y procesar grandes conjuntos de datos en el entrenamiento de redes neuronales.\n",
        "\n",
        "En lugar de cargar todo el conjunto de datos en memoria, el DataLoader carga y procesa los datos de forma iterativa en lotes (batches). Esto significa que sólo se cargan y procesan los datos que se necesitan en cada momento, lo que hace que el entrenamiento sea más eficiente en cuanto al uso de la memoria y al rendimiento.\n",
        "\n",
        "Un DataLoader típicamente toma un conjunto de datos (p. ej., imágenes, texto) y realiza las siguientes tareas:\n",
        "\n",
        "- Cargar los datos del disco en la memoria.\n",
        "\n",
        "- Aplicar transformaciones a los datos (p. ej., normalización, aumento de datos).\n",
        "\n",
        "- Mezclar aleatoriamente los datos.\n",
        "\n",
        "- Agrupar los datos en lotes (batches) de un tamaño determinado.\n",
        "\n",
        "- Preparar los datos para su uso en la red neuronal.\n",
        "\n",
        "En resumen, los DataLoaders son una herramienta esencial en el entrenamiento de modelos de aprendizaje profundo, ya que permiten el procesamiento eficiente de grandes conjuntos de datos, lo que a su vez conduce a una mejor generalización del modelo.\n",
        "\n",
        "\n",
        "```python\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Realizamos aquí cualquier preprocesamiento necesario para la imagen\n",
        "        \n",
        "        return image, label\n",
        "```\n",
        "\n",
        "En el método `__init__` de MyDataset, inicializamos los datos images y labels. En el método `__len__` definimos la longitud del conjunto de datos. En el método `__getitem__` obtenemos los datos de una muestra en particular, realizamos cualquier preprocesamiento necesario en la imagen y devolvemos la imagen y su etiqueta.\n",
        "\n",
        "A continuación, creamos una instancia de MyDataset y lo pasamos al DataLoader.\n",
        "\n",
        "\n",
        "```python\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Definimos los datos\n",
        "images = # array de imágenes\n",
        "labels = # array de etiquetas\n",
        "\n",
        "# Creamos la instancia del dataset\n",
        "dataset = MyDataset(images, labels)\n",
        "\n",
        "# Creamos el DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "```\n",
        "\n",
        "En este ejemplo, definimos los datos images y labels. Creamos una instancia de MyDataset y lo pasamos al DataLoader. Especificamos el tamaño del batch como 32 y shuffle=True para que los datos se mezclen aleatoriamente en cada epoch.\n",
        "\n",
        "Finalmente, podemos iterar a través del DataLoader para obtener los batches de datos.\n",
        "\n",
        "```python\n",
        "for batch_images, batch_labels in dataloader:\n",
        "    # Entrenamos nuestro modelo utilizando los batches de datos\n",
        "```\n",
        "\n",
        "En cada iteración del loop, obtenemos un batch de imágenes y sus etiquetas. Podemos utilizar estos batches para entrenar nuestro modelo.\n"
      ],
      "metadata": {
        "id": "ZzfKhcOzvfpa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrcRtnzaxGng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}